{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/  \n",
    "#            http://zhuanlan.51cto.com/art/201702/531945.htm  \n",
    "# using CART(Classification and Regression Trees,分类回归树算法,简称CART算法)) for classification  \n",
    "  \n",
    "# CART on the Bank Note dataset  \n",
    "from random import seed  \n",
    "from random import randrange  \n",
    "from csv import reader  \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Load a CSV file  \n",
    "def load_csv(filename):  \n",
    "    file = open(filename, \"r\")  \n",
    "    lines = reader(file)  \n",
    "    dataset = list(lines)  \n",
    "    return dataset  \n",
    "  \n",
    "# Convert string column to float  \n",
    "def str_column_to_float(dataset, column):  \n",
    "    for row in dataset:  \n",
    "#         print(type(row), row)\n",
    "        row[column] = float(row[column].strip())  \n",
    "\n",
    "# Split a dataset into k folds  \n",
    "def cross_validation_split(dataset, n_folds):  \n",
    "    dataset_split = list()  \n",
    "    dataset_copy = list(dataset)  \n",
    "    fold_size = int(len(dataset) / n_folds)  \n",
    "    for i in range(n_folds):  \n",
    "        fold = list()  \n",
    "        while len(fold) < fold_size:  \n",
    "            index = randrange(len(dataset_copy))  \n",
    "            fold.append(dataset_copy.pop(index))  \n",
    "        dataset_split.append(fold)  \n",
    "    return dataset_split  \n",
    "  \n",
    "# Calculate accuracy percentage  \n",
    "def accuracy_metric(actual, predicted):  \n",
    "    correct = 0  \n",
    "    for i in range(len(actual)):  \n",
    "        if actual[i] == predicted[i]:  \n",
    "            correct += 1  \n",
    "    return correct / float(len(actual)) * 100.0  \n",
    "  \n",
    "# Evaluate an algorithm using a cross validation split  \n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):  \n",
    "    folds = cross_validation_split(dataset, n_folds)  \n",
    "    scores = list()  \n",
    "    for fold in folds:\n",
    "        train_set = list(folds)  \n",
    "        train_set.remove(fold)  \n",
    "        train_set = sum(train_set, [])  \n",
    "        test_set = list()  \n",
    "        for row in fold:  \n",
    "            row_copy = list(row)  \n",
    "            test_set.append(row_copy)  \n",
    "            row_copy[-1] = None  \n",
    "        predicted = algorithm(train_set, test_set, *args)  \n",
    "        actual = [row[-1] for row in fold]  \n",
    "        accuracy = accuracy_metric(actual, predicted)  \n",
    "        scores.append(accuracy)  \n",
    "    return scores  \n",
    "  \n",
    "# Split a dataset based on an attribute and an attribute value  \n",
    "def test_split(index, value, dataset):  \n",
    "    left, right = list(), list()  \n",
    "    for row in dataset:  \n",
    "        if row[index] < value:  \n",
    "            left.append(row)  \n",
    "        else:  \n",
    "            right.append(row)  \n",
    "    return left, right  \n",
    "  \n",
    "# Calculate the Gini index for a split dataset  \n",
    "def gini_index(groups, classes):  \n",
    "    # count all samples at split point  \n",
    "    n_instances = float(sum([len(group) for group in groups])) # 计算总的样本数  \n",
    "    # sum weighted Gini index for each group  \n",
    "    gini = 0.0  \n",
    "    for group in groups:  \n",
    "        size = float(len(group))  \n",
    "        # avoid divide by zero  \n",
    "        if size == 0:  \n",
    "            continue  \n",
    "        score = 0.0  \n",
    "        # score the group based on the score for each class  \n",
    "        for class_val in classes:  \n",
    "            p = [row[-1] for row in group].count(class_val) / size # row[-1]指每个样本(一行)中最后一列即类别  \n",
    "            score += p * p  \n",
    "        # weight the group score by its relative size  \n",
    "        gini += (1.0 - score) * (size / n_instances)  \n",
    "    return gini  \n",
    "  \n",
    "# Select the best split point for a dataset  \n",
    "def get_split(dataset):  \n",
    "    class_values = list(set(row[-1] for row in dataset)) # class_values的值为: [0, 1]  \n",
    "#     print(class_values)\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None  \n",
    "    for index in range(len(dataset[0])-1): # index的值为: [0, 1, 2, 3]  \n",
    "        for row in dataset:  \n",
    "            groups = test_split(index, row[index], dataset)  \n",
    "            gini = gini_index(groups, class_values)  \n",
    "            if gini < b_score:  \n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups  \n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups} # 返回字典数据类型  \n",
    "  \n",
    "# Create a terminal node value  \n",
    "def to_terminal(group):  \n",
    "    outcomes = [row[-1] for row in group]  \n",
    "    return max(set(outcomes), key=outcomes.count)  \n",
    "  \n",
    "# Create child splits for a node or make terminal  \n",
    "def split(node, max_depth, min_size, depth):  \n",
    "    left, right = node['groups']  \n",
    "    del(node['groups'])  \n",
    "    # check for a no split  \n",
    "    if not left or not right:  \n",
    "        node['left'] = node['right'] = to_terminal(left + right)  \n",
    "        return  \n",
    "    # check for max depth  \n",
    "    if depth >= max_depth:  \n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)  \n",
    "        return  \n",
    "    # process left child  \n",
    "    if len(left) <= min_size:  \n",
    "        node['left'] = to_terminal(left)  \n",
    "    else:  \n",
    "        node['left'] = get_split(left)  \n",
    "        split(node['left'], max_depth, min_size, depth+1)  \n",
    "    # process right child  \n",
    "    if len(right) <= min_size:  \n",
    "        node['right'] = to_terminal(right)  \n",
    "    else:  \n",
    "        node['right'] = get_split(right)  \n",
    "        split(node['right'], max_depth, min_size, depth+1)  \n",
    "  \n",
    "# Build a decision tree  \n",
    "def build_tree(train, max_depth, min_size):  \n",
    "    root = get_split(train)  \n",
    "    split(root, max_depth, min_size, 1)  \n",
    "    return root  \n",
    "  \n",
    "# Make a prediction with a decision tree  \n",
    "def predict(node, row):  \n",
    "    if row[node['index']] < node['value']:  \n",
    "        if isinstance(node['left'], dict):  \n",
    "            return predict(node['left'], row)  \n",
    "        else:  \n",
    "            return node['left']  \n",
    "    else:  \n",
    "        if isinstance(node['right'], dict):  \n",
    "            return predict(node['right'], row)  \n",
    "        else:  \n",
    "            return node['right']  \n",
    "\n",
    "# Classification and Regression Tree Algorithm  \n",
    "def decision_tree(train, test, max_depth, min_size):  \n",
    "    tree = build_tree(train, max_depth, min_size)  \n",
    "    predictions = list()  \n",
    "    for row in test:  \n",
    "        prediction = predict(tree, row)  \n",
    "        predictions.append(prediction)  \n",
    "    return(predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
      "<class 'list'> 40689\n"
     ]
    }
   ],
   "source": [
    "# Test CART on Bank Note dataset  \n",
    "seed(1)  \n",
    "# load and prepare data  \n",
    "filename = './data/training_data.csv' \n",
    "dataset = load_csv(filename)  \n",
    "print(dataset[0])\n",
    "del dataset[0]\n",
    "\n",
    "print(type(dataset) , len(dataset))\n",
    "# convert string attributes to integers  \n",
    "# for i in range(len(dataset[0])):  \n",
    "#     str_column_to_float(dataset, i) # dataset为嵌套列表的列表，类型为float  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "noDataset = []\n",
    "yesDataset = []\n",
    "newdataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for da in dataset:\n",
    "    if da[-1] == \"no\":\n",
    "        noDataset.append(da)\n",
    "    else:\n",
    "        yesDataset.append(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no :  35926   yes :  4763\n",
      "4763 [['55', 'technician', 'married', 'secondary', 'no', '0', 'no', 'no', 'cellular', '27', 'jul', '506', '2', '-1', '0', 'unknown', 'no'], ['60', 'blue-collar', 'married', 'primary', 'no', '1138', 'yes', 'no', 'cellular', '28', 'aug', '116', '4', '-1', '0', 'unknown', 'no']]\n"
     ]
    }
   ],
   "source": [
    "print( \"no : \",len(noDataset), \"  yes : \", len(yesDataset))\n",
    "import random\n",
    "newdataset = random.sample(noDataset, len(yesDataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9526 [['54', 'blue-collar', 'married', 'secondary', 'no', '0', 'no', 'yes', 'cellular', '16', 'jul', '156', '1', '-1', '0', 'unknown', 'no'], ['37', 'admin.', 'married', 'secondary', 'no', '0', 'yes', 'no', 'telephone', '15', 'jul', '280', '6', '-1', '0', 'unknown', 'no'], ['31', 'services', 'single', 'secondary', 'no', '1599', 'no', 'no', 'cellular', '30', 'apr', '226', '1', '78', '2', 'success', 'no'], ['60', 'admin.', 'married', 'secondary', 'no', '106', 'no', 'no', 'cellular', '21', 'aug', '216', '3', '91', '1', 'success', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(len(newdataset), newdataset[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9526 ['46', 'admin.', 'divorced', 'secondary', 'no', '2232', 'no', 'no', 'cellular', '13', 'feb', '121', '1', '-1', '0', 'unknown', 'yes']\n"
     ]
    }
   ],
   "source": [
    "newdataset.extend(yesDataset)\n",
    "random.shuffle(newdataset)\n",
    "print(len(newdataset), newdataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9526 yes\n"
     ]
    }
   ],
   "source": [
    "label = [newdata[-1] for newdata in newdataset]\n",
    "print(len(label), label[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate algorithm  \n",
    "# n_folds = 12  \n",
    "max_depth = 4  \n",
    "min_size = 2  \n",
    "\n",
    "newdataset1000 = random.sample(newdataset, 1500)\n",
    "label1000 = random.sample(label, 1500)\n",
    "# scores = excute(newdataset1000, decision_tree, n_folds, max_depth, min_size)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 s, sys: 7.99 ms, total: 31.2 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# scores = decision_tree(newdataset1000, newdataset1000[:500], max_depth, min_size)\n",
    "train = newdataset1000\n",
    "tree = build_tree(train, max_depth, min_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: ['yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes']\n",
      "50.2\n"
     ]
    }
   ],
   "source": [
    "test=  newdataset1000[:500]\n",
    "predictions = list()  \n",
    "for row in test:  \n",
    "    prediction = predict(tree, row)  \n",
    "    predictions.append(prediction)  \n",
    "scores = predictions\n",
    "accuracy = accuracy_metric(label1000[:500], scores)  \n",
    "print('Scores: %s' % scores[:10])  \n",
    "print(accuracy)\n",
    "# print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
      "4522 [0, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "filename = './data/testing_data.csv' \n",
    "testdataset = load_csv(filename)  \n",
    "print(testdataset[0])\n",
    "del testdataset[0]\n",
    "\n",
    "res = list()  \n",
    "for row in testdataset:  \n",
    "    prediction = predict(tree, row)  \n",
    "    if prediction == \"yes\":\n",
    "        res.append(1)  \n",
    "    elif prediction == \"no\":\n",
    "        res.append(0) \n",
    "print(len(res), res[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count how many people will Deposit: \n",
      "2264 test predict result Deposit percentage : 0.5324553151458138\n"
     ]
    }
   ],
   "source": [
    "# csvfile = \"result\" + str(datetime.now()).split()[1] + \".csv\"\n",
    "res_csv_file_path = \"result_decision_tree.csv\"\n",
    "\n",
    "with open(res_csv_file_path, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(('id', 'ans'))\n",
    "    ids = 0\n",
    "    for val in res:\n",
    "        writer.writerow((str(ids), str(val)))\n",
    "        ids += 1\n",
    "\n",
    "print(\"Count how many people will Deposit: \")\n",
    "with open(res_csv_file_path) as csvfile:\n",
    "    counts = 0\n",
    "    train_csv = csv.DictReader(csvfile)\n",
    "    for row in train_csv:\n",
    "        if row[\"ans\"]  == \"1\":\n",
    "#             print(row[\"id\"])\n",
    "            counts += 1\n",
    "print(counts, \"test predict result Deposit percentage :\" , counts / 4252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
