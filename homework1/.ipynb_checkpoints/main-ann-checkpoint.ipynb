{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = './data/training_data.csv'\n",
    "testing_file_path = './data/testing_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv  = None\n",
    "with open(train_file_path) as csvfile:\n",
    "    train_csv = csv.DictReader(csvfile)\n",
    "    for row in train_csv:\n",
    "        print(type(row), row)\n",
    "        break\n",
    "    print(type(train_csv))\n",
    "\n",
    "with open(testing_file_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row['Colour'] == 'blue':\n",
    "            print(row['ID'] ,row ['Make'],row ['Colour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense, Dropout\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "TRAIN_FILE_PATH= train_file_path\n",
    "TEST_FILE_PATH= testing_file_path\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_FILE_PATH)\n",
    "test_df = pd.read_csv(TEST_FILE_PATH)\n",
    "\n",
    "\n",
    "train_cols = ['age', 'job', 'marital','education', 'default', 'balance', 'housing', 'loan'\n",
    "       , 'contact','day', 'month', 'duration', 'campaign', 'pdays' , 'previous', 'poutcome', \"y\"]\n",
    "test_cols = ['age', 'job', 'marital','education', 'default', 'balance', 'housing', 'loan'\n",
    "       , 'contact','day', 'month', 'duration', 'campaign', 'pdays' , 'previous', 'poutcome']\n",
    "\n",
    "train_df = train_df[train_cols]\n",
    "\n",
    "test_df = test_df[test_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ss\" != \"ss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40689\n",
      "40689 4763  Deposit percentage : 0.11705866450391998\n",
      "5841 4763  Deposit percentage : 0.815442561205273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "def PreprocessData(raw_df , data_type):\n",
    "    #Remove the 'name' col 雙親或子女在船上的數量、 Ticket\n",
    "    df = raw_df.drop(['default'], axis=1)\n",
    "#     df = raw_df.drop(['month'], axis=1)\n",
    "     \n",
    "    for s in df['job']:\n",
    "        if  s != \"services\" and s != \"student\" and s != \"unemployed\" and s != \"admin.\" and s != \"technician\" and s != \"unknown\"  and  s != \"blue-collar\" and s != \"housemaid\" and  s != \"entrepreneur\"  and s != \"self-employed\" and s != \"retired\" and  s != \"management\"  :\n",
    "                print(s, type(s))\n",
    "    print(type(df['marital'][0]), df['marital'][0])\n",
    "    df['job'] = df['job'].map({\"unknown\" : 0, 'services': 1, 'admin.': 30, 'technician': 40,'blue-collar': 4, \n",
    "                               'housemaid': 5, 'entrepreneur': 6, 'self-employed': 7, 'retired': 8,\n",
    "                               'management': 31, \"student\" : 32, \"unemployed\" : 11}).astype(int)\n",
    "    df['marital'] = df['marital'].map({ 'divorced': 5 , 'single': 10, 'married': 2}).astype(int)\n",
    "    df['education'] = df['education'].map({ 'secondary': 0 , 'primary': 1, 'tertiary': 2, \"unknown\" :3}).astype(int)\n",
    "#     df['balance'] = df['marital'].map({ 'divorced': 0 , 'single': 1, 'married.': 2}).astype(int)\n",
    "    df['housing'] = df['housing'].map({ 'no': 0 , 'yes': 1, 'married.': 2}).astype(int)\n",
    "    df['loan'] = df['loan'].map({ 'no': 0 , 'yes': 1, 'married.': 2}).astype(int)\n",
    "    df['contact'] = df['contact'].map({ 'unknown': 0 , 'telephone': 1, 'cellular': 2}).astype(int)\n",
    "#     df['day'] = df['marital'].map({ 'divorced': 0 , 'single': 1, 'married.': 2}).astype(int)\n",
    "    df['month'] = df['month'].map({ 'jan': 1, 'feb': 2, 'mar': 3 , 'apr': 4 , 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,'sep': 9, 'oct': 10 , 'nov': 11, 'dec': 12}).astype(int)\n",
    "#     df['duration'] = df['marital'].map({ 'divorced': 0 , 'single': 1, 'married.': 2}).astype(int)\n",
    "#     df['campaign'] = df['marital'].map({ 'divorced': 0 , 'single': 1, 'married.': 2}).astype(int)\n",
    "#     df['pdays'] = df['marital'].map({ 'divorced': 0 , 'single': 1, 'married.': 2}).astype(int)\n",
    "#     df['previous'] = df['marital'].map({ 'divorced': 0 , 'single': 1, 'married.': 2}).astype(int)\n",
    "    df['poutcome'] = df['poutcome'].map({ 'failure': 0 , 'success': 1, 'unknown': 2, 'other': 3}).astype(int)\n",
    "    \n",
    "    df['balance'] = df['balance'] /100.0\n",
    "    \n",
    "    df['age'] = df['age'] / 5.0\n",
    "    \n",
    "    df['duration'] = df['duration'] /100.0\n",
    "#     print(df['duration'])\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        df['y'] = df['y'].map({ 'no': 0 , 'yes': 1}).astype(int)\n",
    "        print(len(df))\n",
    "        df1 = df[df.y.isin([1])]\n",
    "        print(len(df), len(df1),\" Deposit percentage :\" , len(df1)/ len(df))\n",
    "        \n",
    "        df0 = df[df.y.isin([0])].sample(frac=0.03) \n",
    "        newdf = df1.append(df0).sample(frac=1) \n",
    "        print(len(newdf), len(df1),\" Deposit percentage :\" , len(df1)/ len(newdf))\n",
    "#         print(\"df[y] : \" ,newdf['y'])\n",
    "    else:\n",
    "        df['y'] = 0\n",
    "\n",
    "    x_OneHot_df = pd.get_dummies(data=df, columns = [])\n",
    "    ndarray = x_OneHot_df.values\n",
    "    \n",
    "    label = ndarray[:,14]  \n",
    "    Features = ndarray[:,1:] \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    scaledFeatures = minmax_scale.fit_transform(Features)\n",
    "    \n",
    "    return scaledFeatures, label\n",
    "\n",
    "# boat_val = test_df[\"boat\"]\n",
    "train_result, train_label = PreprocessData(train_df, \"train\")\n",
    "test_feature, test_label = PreprocessData(test_df , \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 4)                 404       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,009\n",
      "Trainable params: 2,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, input_dim= 15, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=4, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=1, kernel_initializer='uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36620 samples, validate on 4069 samples\n",
      "Epoch 1/10\n",
      "36620/36620 [==============================] - 1s 27us/step - loss: 0.6360 - acc: 0.0335 - val_loss: 0.5108 - val_acc: 0.0349\n",
      "Epoch 2/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: 0.0736 - acc: 0.0329 - val_loss: -0.6763 - val_acc: 0.0349\n",
      "Epoch 3/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: -2.0387 - acc: 0.0329 - val_loss: -3.8577 - val_acc: 0.0349\n",
      "Epoch 4/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: -6.9177 - acc: 0.0329 - val_loss: -10.6646 - val_acc: 0.0349\n",
      "Epoch 5/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: -12.1609 - acc: 0.0329 - val_loss: -12.3600 - val_acc: 0.0349\n",
      "Epoch 6/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: -12.5927 - acc: 0.0329 - val_loss: -12.4029 - val_acc: 0.0349\n",
      "Epoch 7/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: -12.6185 - acc: 0.0329 - val_loss: -12.4185 - val_acc: 0.0349\n",
      "Epoch 8/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: -12.6365 - acc: 0.0329 - val_loss: -12.4372 - val_acc: 0.0349\n",
      "Epoch 9/10\n",
      "36620/36620 [==============================] - 0s 6us/step - loss: -12.6806 - acc: 0.0329 - val_loss: -12.5278 - val_acc: 0.0349\n",
      "Epoch 10/10\n",
      "36620/36620 [==============================] - 0s 5us/step - loss: -12.8766 - acc: 0.0329 - val_loss: -12.8639 - val_acc: 0.0349\n",
      "40689/40689 [==============================] - 10s 244us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x = train_result, y = train_label, epochs = 10, validation_split = 0.1, batch_size = 1000, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1732363240177318, 0.9301285400560757]\n",
      "153 test predict result Deposit percentage : 0.03598306679209784\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(test_feature, batch_size=5, verbose=0)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvfile = \"result\" + str(datetime.now()).split()[1] + \".csv\"\n",
    "res_csv_file_path = \"result.csv\"\n",
    "\n",
    "with open(res_csv_file_path, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(('id', 'ans'))\n",
    "    ids = 0\n",
    "    for val in res:\n",
    "        if val[0] > 0.2:\n",
    "            writer.writerow((str(ids), str(1)))\n",
    "        else:\n",
    "            writer.writerow((str(ids), str(0)))\n",
    "        ids += 1\n",
    "\n",
    "print(\"Count how many people will Deposit: \")\n",
    "with open(res_csv_file_path) as csvfile:\n",
    "    counts = 0\n",
    "    train_csv = csv.DictReader(csvfile)\n",
    "    for row in train_csv:\n",
    "        if row[\"ans\"]  == \"1\":\n",
    "#             print(row[\"id\"])\n",
    "            counts += 1\n",
    "print(counts, \"test predict result Deposit percentage :\" , counts / 4252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count how many people will Deposit: \n",
      "153\n",
      "153 test predict result Deposit percentage : 0.03598306679209784\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
